{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72c8856-d521-4620-8d42-0054bcbc6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================\n",
    "# Title:  Climate Credit Risk Model\n",
    "# Author: Vachan\n",
    "# Email : vachan@iitb.ac.in\n",
    "#=========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e81964-3d94-4305-8dd5-42e963de2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f2b1dc-5b4a-456d-8c80-dfee7e236dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_future_data(base_data, best_model_vars, years_to_simulate=4):\n",
    "    \"\"\"\n",
    "    Simulates future data for each customer_id based on logical trends for years 2022-2025.\n",
    "\n",
    "    Args:\n",
    "        base_data (pd.DataFrame): The original dataframe to base simulations on. \n",
    "                                  Must contain a 'customer_id' column.\n",
    "        best_model_vars (list): The list of variables to simulate.\n",
    "        years_to_simulate (int): The number of future years to simulate (e.g., 4 for 2022-2025).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing the original and simulated data for 2021-2025.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Future Data Simulation (per customer) for 2022-2025 ---\")\n",
    "    \n",
    "    if 'customer_id' not in base_data.columns:\n",
    "        raise ValueError(\"The base data must contain a 'customer_id' column.\")\n",
    "\n",
    "    # Start with the 2021 data.\n",
    "    last_known_data = base_data.copy()\n",
    "    if 'year' not in last_known_data.columns:\n",
    "        last_known_data['year'] = 2021\n",
    "    \n",
    "    # Ensure credit_history is numeric for simulation\n",
    "    if 'credit_history' in best_model_vars:\n",
    "        last_known_data['credit_history'] = pd.to_numeric(last_known_data['credit_history'], errors='coerce').fillna(0)\n",
    "\n",
    "    future_data_list = [last_known_data] # Include the base year in the list\n",
    "\n",
    "    for year_offset in range(1, years_to_simulate + 1):\n",
    "        future_year = 2021 + year_offset\n",
    "        print(f\"Simulating data for year: {future_year}\")\n",
    "        \n",
    "        future_df = last_known_data.copy()\n",
    "        future_df['year'] = future_year\n",
    "\n",
    "        # --- Simulation Logic (applied to the previous year's data) ---\n",
    "        if 'ltv' in best_model_vars:\n",
    "            future_df['ltv'] *= np.random.uniform(0.95, 0.99, size=len(future_df))\n",
    "\n",
    "        if 'average_age' in best_model_vars:\n",
    "            future_df['average_age'] += 1\n",
    "\n",
    "        if 'credit_score' in best_model_vars:\n",
    "            future_df['credit_score'] *= np.random.uniform(1.0, 1.02, size=len(future_df))\n",
    "            future_df['credit_score'] = future_df['credit_score'].clip(upper=900)\n",
    "\n",
    "        if 'last_six_month_defaulted_no' in best_model_vars:\n",
    "            future_df['last_six_month_defaulted_no'] = np.random.choice([0, 1], size=len(future_df), p=[0.98, 0.02])\n",
    "            \n",
    "        if 'credit_history' in best_model_vars:\n",
    "            future_df['credit_history'] += 1\n",
    "\n",
    "        future_data_list.append(future_df)\n",
    "        last_known_data = future_df.copy()\n",
    "    \n",
    "    full_simulated_df = pd.concat(future_data_list, ignore_index=True)\n",
    "    \n",
    "    print(\"\\n--- Simulation Complete ---\")\n",
    "    return full_simulated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af821862-9e51-4539-bcda-86f32f2ff35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ngfs_data_for_country(file_path, country_name, ngfs_variable_vector, years_to_extract):\n",
    "    \"\"\"\n",
    "    Loads and filters NGFS data from an Excel file for a specific country, \n",
    "    handling different scenarios correctly.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loading NGFS data from {file_path} for {country_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        df.columns = [str(col).strip() for col in df.columns]\n",
    "        \n",
    "        required_cols = ['Region', 'Scenario', 'Variable']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            raise ValueError(f\"The Excel file must contain {required_cols} columns.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or parsing the Excel file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    country_df = df[df['Region'] == country_name]\n",
    "    filtered_df = country_df[country_df['Variable'].isin(ngfs_variable_vector)]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    id_vars = ['Region', 'Scenario', 'Variable']\n",
    "    year_cols = [str(y) for y in years_to_extract]\n",
    "    value_vars = [col for col in year_cols if col in filtered_df.columns]\n",
    "    \n",
    "    if not value_vars:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    melted_df = filtered_df.melt(id_vars=id_vars, value_vars=value_vars, var_name='year', value_name='value')\n",
    "    pivoted_df = melted_df.pivot_table(index=['year', 'Scenario'], columns='Variable', values='value').reset_index()\n",
    "    pivoted_df['year'] = pd.to_numeric(pivoted_df['year']).astype(int)\n",
    "    \n",
    "    print(\"NGFS data loaded and transformed successfully.\")\n",
    "    return pivoted_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55125049-d887-4db8-8149-536937b2b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_risk_drivers(customer_data, explanatory_data, dependent_vars, explanatory_vars):\n",
    "    \"\"\"\n",
    "    Trains models on the 'Baseline' scenario for 2021-2025 and predicts \n",
    "    2026 values for all scenarios using an aggregation approach to avoid memory errors.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n--- Starting Model Training and Prediction ---\")\n",
    "    \n",
    "    # Aggregate customer data by year to prevent memory errors\n",
    "    avg_customer_data = customer_data.groupby('year')[dependent_vars].mean().reset_index()\n",
    "    \n",
    "    # Prepare training data (2021-2025, Baseline only)\n",
    "    merged_data = pd.merge(avg_customer_data, explanatory_data, on='year', how='left')\n",
    "    train_data = merged_data[merged_data['Scenario'] == 'Baseline'].copy()\n",
    "    \n",
    "    # Prepare prediction input data (2026, all scenarios)\n",
    "    prediction_inputs = explanatory_data[explanatory_data['year'] == 2026].copy()\n",
    "\n",
    "    if prediction_inputs.empty:\n",
    "        print(\"CRITICAL WARNING: No NGFS data found for the prediction year (2026). Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    for dep_var in dependent_vars:\n",
    "        print(f\"\\n==================== Processing Risk Driver: {dep_var} ====================\")\n",
    "        \n",
    "        # Find the Best Model using 'Baseline' Data\n",
    "        lowest_aic = float('inf')\n",
    "        best_model = None\n",
    "        best_combination = None\n",
    "        \n",
    "        print(\"\\n--- Finding best model on 'Baseline' data (2021-2025) ---\")\n",
    "        for i in range(1, len(explanatory_vars) + 1):\n",
    "            for combo in combinations(explanatory_vars, i):\n",
    "                combo_list = list(combo)\n",
    "                \n",
    "                model_data = train_data[[dep_var] + combo_list].dropna()\n",
    "                if len(model_data) < len(combo_list) + 2:\n",
    "                    continue\n",
    "\n",
    "                X_train = model_data[combo_list]\n",
    "                y_train = model_data[dep_var]\n",
    "                X_train = sm.add_constant(X_train, has_constant='add')\n",
    "\n",
    "                try:\n",
    "                    model = sm.OLS(y_train, X_train).fit()\n",
    "                    if model.aic < lowest_aic:\n",
    "                        lowest_aic = model.aic\n",
    "                        best_model = model\n",
    "                        best_combination = combo_list\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        if best_model is None:\n",
    "            print(f\"Could not find a suitable model for '{dep_var}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Best model for '{dep_var}' found with combination: {best_combination}\")\n",
    "        print(f\"Lowest AIC: {lowest_aic:.4f}\")\n",
    "\n",
    "        # Predict for 2026 under ALL Scenarios\n",
    "        print(\"\\n--- Predicting 2026 values for all scenarios ---\")\n",
    "        \n",
    "        X_predict = prediction_inputs[best_combination]\n",
    "        X_predict = sm.add_constant(X_predict, has_constant='add')\n",
    "        \n",
    "        predictions = best_model.predict(X_predict)\n",
    "        \n",
    "        scenario_predictions = prediction_inputs[['Scenario']].copy()\n",
    "        scenario_predictions['risk_driver'] = dep_var\n",
    "        scenario_predictions['predicted_value_2026'] = predictions\n",
    "        all_predictions.append(scenario_predictions)\n",
    "\n",
    "    # --- Display and Save Final Predictions ---\n",
    "    if all_predictions:\n",
    "        final_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "\n",
    "        # Save the results to a CSV file\n",
    "        predicted_drivers_file = 'predicted_risk_drivers_2026.csv'\n",
    "        final_predictions_df.to_csv(predicted_drivers_file, index=False)\n",
    "        print(f\"\\n--- Predicted risk drivers for 2026 saved to {predicted_drivers_file} ---\")\n",
    "\n",
    "        print(\"\\n\\n==================== FINAL 2026 PREDICTIONS ====================\")\n",
    "        prediction_summary = final_predictions_df.pivot_table(\n",
    "            index='Scenario',\n",
    "            columns='risk_driver',\n",
    "            values='predicted_value_2026'\n",
    "        )\n",
    "        print(prediction_summary)\n",
    "    else:\n",
    "        print(\"\\nNo predictions were generated.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ca2725-21a1-4148-9daa-62959d2fcf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading NGFS data from C:/Users/vacha/OneDrive - Indian Institute of Technology Bombay/Climate Finance/Retail Portfoilio Research/GEME3_IIASA_2025_05_02.xlsx for India - IND ---\n",
      "NGFS data loaded and transformed successfully.\n",
      "--- Starting Future Data Simulation (per customer) for 2022-2025 ---\n",
      "Simulating data for year: 2022\n",
      "Simulating data for year: 2023\n",
      "Simulating data for year: 2024\n",
      "Simulating data for year: 2025\n",
      "\n",
      "--- Simulation Complete ---\n",
      "\n",
      "\n",
      "--- Starting Model Training and Prediction ---\n",
      "\n",
      "==================== Processing Risk Driver: ltv ====================\n",
      "\n",
      "--- Finding best model on 'Baseline' data (2021-2025) ---\n",
      "Best model for 'ltv' found with combination: ['Imports|Crude Oil', 'Production|EV Transport Equipment', 'Unemployment Rate']\n",
      "Lowest AIC: -27.1436\n",
      "\n",
      "--- Predicting 2026 values for all scenarios ---\n",
      "\n",
      "==================== Processing Risk Driver: average_age ====================\n",
      "\n",
      "--- Finding best model on 'Baseline' data (2021-2025) ---\n",
      "Best model for 'average_age' found with combination: ['Imports|Crude Oil', 'Production|EV Transport Equipment', 'Unemployment Rate']\n",
      "Lowest AIC: -34.9337\n",
      "\n",
      "--- Predicting 2026 values for all scenarios ---\n",
      "\n",
      "==================== Processing Risk Driver: credit_score ====================\n",
      "\n",
      "--- Finding best model on 'Baseline' data (2021-2025) ---\n",
      "Best model for 'credit_score' found with combination: ['Expenditure|Household|Purchase of vehicles', 'Expenditure|Household|Transport services', 'Imports|Crude Oil']\n",
      "Lowest AIC: -19.8800\n",
      "\n",
      "--- Predicting 2026 values for all scenarios ---\n",
      "\n",
      "==================== Processing Risk Driver: last_six_month_defaulted_no ====================\n",
      "\n",
      "--- Finding best model on 'Baseline' data (2021-2025) ---\n",
      "Best model for 'last_six_month_defaulted_no' found with combination: ['Expenditure|Household|Purchase of vehicles', 'Exports|EV Transport Equipment', 'Investments|EV Transport Equipment']\n",
      "Lowest AIC: -81.2542\n",
      "\n",
      "--- Predicting 2026 values for all scenarios ---\n",
      "\n",
      "==================== Processing Risk Driver: credit_history ====================\n",
      "\n",
      "--- Finding best model on 'Baseline' data (2021-2025) ---\n",
      "Best model for 'credit_history' found with combination: ['Imports|Crude Oil', 'Production|EV Transport Equipment', 'Unemployment Rate']\n",
      "Lowest AIC: -34.9337\n",
      "\n",
      "--- Predicting 2026 values for all scenarios ---\n",
      "\n",
      "--- Predicted risk drivers for 2026 saved to predicted_risk_drivers_2026.csv ---\n",
      "\n",
      "\n",
      "==================== FINAL 2026 PREDICTIONS ====================\n",
      "risk_driver      average_age  credit_history  credit_score  \\\n",
      "Scenario                                                     \n",
      "Baseline           13.087839       18.220607    306.383883   \n",
      "DAPS_AFR_R         12.091243       17.224011    306.340664   \n",
      "DAPS_AFR_R_run1    12.236019       17.368787    305.958696   \n",
      "DAPS_ASIA          32.997454       38.130222    303.782682   \n",
      "DAPS_ASIA_run1     19.128394       24.261162    304.450924   \n",
      "DAPS_EUR           12.673199       17.805967    306.488932   \n",
      "DAPS_EUR_run1      12.887705       18.020473    306.183977   \n",
      "DAPS_NAM           12.467206       17.599974    306.790317   \n",
      "DAPS_NAM_run1      12.963385       18.096153    306.232746   \n",
      "DAPS_OCE           12.895895       18.028662    306.394218   \n",
      "DAPS_OCE_run1      12.930976       18.063744    306.357649   \n",
      "DAPS_SAM           12.975233       18.108001    306.313259   \n",
      "DAPS_SAM_run1      12.978370       18.111138    306.304751   \n",
      "DIRE               23.694563       28.827331    305.136714   \n",
      "DIRE_run1          13.359409       18.492177    305.887854   \n",
      "HWTP               20.287775       25.420543    305.383206   \n",
      "HWTP_run1          18.478780       23.611548    305.347819   \n",
      "SWUC               13.087839       18.220607    306.383883   \n",
      "SWUC_run1          13.087839       18.220607    306.383883   \n",
      "\n",
      "risk_driver      last_six_month_defaulted_no        ltv  \n",
      "Scenario                                                 \n",
      "Baseline                            0.015403  63.986439  \n",
      "DAPS_AFR_R                          0.014839  66.577684  \n",
      "DAPS_AFR_R_run1                     0.014470  66.169783  \n",
      "DAPS_ASIA                           0.012242  10.427448  \n",
      "DAPS_ASIA_run1                      0.008751  47.485861  \n",
      "DAPS_EUR                            0.015520  65.088639  \n",
      "DAPS_EUR_run1                       0.015255  64.524199  \n",
      "DAPS_NAM                            0.014871  65.625460  \n",
      "DAPS_NAM_run1                       0.015219  64.305912  \n",
      "DAPS_OCE                            0.015368  64.490278  \n",
      "DAPS_OCE_run1                       0.015346  64.397434  \n",
      "DAPS_SAM                            0.015330  64.280393  \n",
      "DAPS_SAM_run1                       0.015325  64.272317  \n",
      "DIRE                               -0.008574  35.542732  \n",
      "DIRE_run1                          -0.011056  63.181994  \n",
      "HWTP                               -1.824624  44.176472  \n",
      "HWTP_run1                          -1.812314  49.002936  \n",
      "SWUC                                0.015403  63.986439  \n",
      "SWUC_run1                           0.015403  63.986439  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "       # --- Define File Paths and Variables ---\n",
    "        customer_data_file = \"C:/Users/vacha/OneDrive - Indian Institute of Technology Bombay/Climate Finance/Retail Portfoilio Research/Auto Risk Kaggle/data.csv\"\n",
    "        ngfs_data_file = \"C:/Users/vacha/OneDrive - Indian Institute of Technology Bombay/Climate Finance/Retail Portfoilio Research/GEME3_IIASA_2025_05_02.xlsx\" # <--- CHANGE THIS PATH\n",
    "\n",
    "        ngfs_variables_to_use = [\n",
    "            'Imports|Crude Oil',\n",
    "            'Crude Oil YoY Growth',\n",
    "            'Expenditure|Household|Transport services',\n",
    "            'Investment|Energy',\n",
    "            'Exports|EV Transport Equipment',\n",
    "            'Production|EV Transport Equipment',\n",
    "            'Investments|EV Transport Equipment',\n",
    "            'Expenditure|Household|Purchase of vehicles',\n",
    "            'Power Generation Technologies|Oil fired',\n",
    "            'Unemployment Rate'\n",
    "        ]\n",
    "\n",
    "        best_model_variables = [\n",
    "            'ltv', 'average_age', 'credit_score', \n",
    "            'last_six_month_defaulted_no', 'credit_history']\n",
    "    # --- 1. Load Data ---\n",
    "        df = pd.read_csv(customer_data_file)\n",
    "        \n",
    "        # Load NGFS data for training (2021-2025) and prediction (2026)\n",
    "        explanatory_df = load_ngfs_data_for_country(\n",
    "            file_path=ngfs_data_file,\n",
    "            country_name='India - IND',\n",
    "            ngfs_variable_vector=ngfs_variables_to_use,\n",
    "            years_to_extract=[2021, 2022, 2023, 2024, 2025, 2026]\n",
    "        )\n",
    "        \n",
    "        if explanatory_df.empty:\n",
    "            raise ValueError(\"Failed to load explanatory data. Check file path, country name, and variable names.\")\n",
    "\n",
    "        df.dropna(subset=best_model_variables, inplace=True)\n",
    "\n",
    "        # --- 2. Simulate Customer-Level Data up to 2025 ---\n",
    "        customer_data_simulated = simulate_future_data(df, best_model_variables, years_to_simulate=4)\n",
    "        \n",
    "        # --- 3. Train Models on Baseline and Predict for 2026 ---\n",
    "        explanatory_variable_vector = [col for col in explanatory_df.columns if col not in ['year', 'Scenario']]\n",
    "\n",
    "        train_and_predict_risk_drivers(\n",
    "            customer_data_simulated,\n",
    "            explanatory_df,\n",
    "            best_model_variables, \n",
    "            explanatory_variable_vector\n",
    "        )\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nError: A required file was not found. Details: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
